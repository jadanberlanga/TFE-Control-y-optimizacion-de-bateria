import json,os,random, time
import numpy as np
import pandas as pd
from datetime import datetime
import datos_temperatura as temperaturas
import emparejar_datos_endesa_omie as emparejarEO
import matplotlib.pyplot as plt

import statsmodels.api as sm
from statsmodels.tsa.statespace.sarimax import SARIMAX


import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
from torch.utils.data import DataLoader


def comprobacion_hardware_y_modo(parametros):
    """
    \nRealiza una comprobaci√≥n del entorno de hardware y de los archivos de modelos de IA necesarios.

    \nFlujo:
    \n1) Verifica la disponibilidad de hardware compatible con CUDA y la presencia de la librer√≠a `torch` (PyTorch):
        - Si hay GPU + CUDA + PyTorch, activa el modo GPU.
        - Si falta alguna de esas cosas, autom√°ticamente a CPU.
    \n2) Comprueba si existen los tres modelos de IA necesarios en disco (rutas proporcionadas en el diccionario de par√°metros):
        - Modelo de demanda (Edistribucion), solar (pysolar) y de precio (OMIE).
        - Si los tres archivos existen, se activa `tengo_modelos=True`.
        - Si falta alguno, `tengo_modelos=False` y el sistema usar√° un predictor cl√°sico (modelo ARIMA).

    \nNotas:
    \n- No realiza c√°lculos ni carga modelos a√∫n, solo hace la comprobaci√≥n de hardware y presencia de archivos.

    \nPar√°metros:
    \n- parametros : dict, JSON de configuraci√≥n ya cargado, que debe contener en su campo `"rutas_modelos_IA"` las rutas de los modelos de demanda, solar y precio.

    \nReturns:
    \n- Tuple[bool, bool] :
        - `tengo_gpu`: True si hay GPU + CUDA + PyTorch disponible.
        - `tengo_modelos`: True si los tres modelos de IA existen en las rutas indicadas.
    """

    #Comprobard hardware
    tengo_gpu = False #modo cpu por defecto, ya cambiere
    try:
        import torch
        if torch.cuda.is_available():
            print("\n-> GPU + CUDA + PYTORCH disponibles, usando la GPU")
            tengo_gpu = True
        else:
            print("\n-> GPU CUDA -NO- disponible, cambiando a CPU")
            tengo_gpu = False
    except ImportError:
        print("\n-> PyTorch no est√° instalado, cambiando a CPU.")
        tengo_gpu = False


    #Comprobar archivos de IA
    tengo_modelos = False #asumo que no tengo los modelos, ya mirare si los tengo
    ruta_modelo_demanda = parametros["rutas_modelos_IA"]["modelo_demanda"]
    ruta_modelo_solar = parametros["rutas_modelos_IA"]["modelo_solar"]
    ruta_modelo_precio = parametros["rutas_modelos_IA"]["modelo_precio"]

    # ver si los tres archivos existen, si no deja en false
    if all(os.path.exists(ruta) for ruta in [ruta_modelo_demanda, ruta_modelo_solar, ruta_modelo_precio]):
        tengo_modelos = True

    return tengo_gpu,tengo_modelos



class ForecastSingleFeatureDataset(Dataset):
    """
    \nDataset personalizado de PyTorch para el entrenamiento de modelos de predicci√≥n de series temporales horarias (forecast de una sola variable objetivo a 24h vista), usando como input tanto datos del d√≠a actual como de los 14 d√≠as previos.
    (el mismo dataset y arquitectura de modelo de IA para las 3 variables, solo paso datos distintos)
    \nEste dataset genera, para cada muestra:
    - Una entrada `x` con dos partes:
        1) Datos del d√≠a actual (`canales_dia_actual`), incluyendo codificaciones de fecha, hora y temperatura
        (tengo todos los datos menos el de la variable objetivo de hoy. En entrenamiento tedre dicho dato pero lo usare para evaluar, no para entrenar).
        2) Un hist√≥rico de los 14 d√≠as anteriores (`historico_ordenado`), donde se incluyen las mismas variables, adem√°s de la variable objetivo de esos d√≠as (es decir, una variable mas, un canal extra, no son compatibles ambas entradas).
    - Un objetivo `y`: la variable de predicci√≥n, ejemplo la demanda el√©ctrica.

    \nFlujo interno:
    \n1) El dataset espera como entrada un tensor `entradas` de tama√±o `[N_dias, 8, 24]`, donde:
        - Canal 0: Hora_sin
        - Canal 1: Hora_cos
        - Canal 2: Dia_sin
        - Canal 3: Dia_cos
        - Canal 4: Mes_sin
        - Canal 5: Mes_cos
        - Canal 6: Temperatura (u otro input adicional por hora)
        - Canal 7: Variable objetivo a predecir (demanda, solar, precio, etc.). No se la pasare al modelo en si, solo la uso para evaluar durante el entrenamiento
\nMe interesa pasarle que dia concreto del a√±o estoy, pero los numero de 1 a 24, de 0 a 6 etc. Esto puede confundir al modelo,
no identificando correctamente que ese valor se trata del dia y en su lugar pensar que la diferencia del dia 1 al 30 es abismal
porque en uno pone 30 y en otro 1, por ejemplo. Para ello hago una conversion a senos y cosenos
(ya que son simetricas necesito 2 funciones para identificar a un valor unico, ejemplo cos 0 = cos 180 = 0. Pero el seno de ambos si es distinto, +-1 respectivamente),
que normaliza y tiene ya un "patron temporal".

\n2) Para cada √≠ndice:
        - Recupera los datos del d√≠a actual y los 14 d√≠as anteriores (por eso el tama√±o del dataset es `N_dias - 15`).
        - Genera un vector con las variables del d√≠a actual en formato `[7, 24]`. ( 7 variables, 1 dia, 24 horas, una matriz 2d, vease una tabla)
        - Genera el hist√≥rico completo de `[8, 14, 24]` (8 variables, 14 dias, 24 horas, una matriz 3d basicamente), donde el canal 7 del hist√≥rico representa la evoluci√≥n de la variable objetivo.
        - Aplica ruido aleatorio en un 20% de las muestras (par√°metro `ruido_usado` escala ese ruido). Este ruido afecta tanto al objetivo como al hist√≥rico, para evitar overfitting.
        Tengo pocos datos, y en una red relativamente compleja puede "memorizar" todos los valores y no aprender a predecir en la realidad. Con el ruido (un un dropout en el entrenamiento) evito esto, tengo "datos nuevos infinitos", pero de peor calidad (ruido, no reales)
        - El objetivo (`y`) se obtiene como el vector de 24 horas de la variable objetivo del d√≠a actual, con el mismo ruido aplicado.

    \nPar√°metros de inicializaci√≥n:
    - entradas : torch.Tensor, Tensor de entrada de tama√±o `[N_dias, 8, 24]`, preprocesado previamente.
    - ruido_usado : float,  Escala del ruido relativo que se aplicar√° a la variable objetivo. Ejemplo: `0.01` aplicar√° un 1% de ruido (recordatorio que no a todas las muestras se les aplica ruido, sol al 20%).

    \nDevuelve en cada `__getitem__`:
    - Un tuple de 2 elementos:
        1) Diccionario:
            - `"actuales"` : Tensor `[7, 24]`: Variables del d√≠a actual (sin incluir la variable objetivo).
            - `"historico"` : Tensor `[8, 14, 24]`: Hist√≥rico de 14 d√≠as, incluyendo la variable objetivo como √∫ltimo canal.
        2) Tensor `objetivo`: Tensor `[24]`: Vector objetivo a predecir (por defecto la demanda, pero depende del dataset usado).

    \nNotas:
    - El ruido se aplica tanto al hist√≥rico como al objetivo del d√≠a actual. El mismo ruido, para eliminar todas las variables aleatorias posibles al empeorar la "calidad" de los datos a cambio de cantidad.
    - Los canales del d√≠a actual **no** incluyen la variable objetivo (se quita expl√≠citamente, solo esta ahi para la evaluacion durante el entrenamiento).
    - El dataset espera recibir d√≠as suficientes para poder hacer slicing con 14 d√≠as previos m√°s el d√≠a objetivo (por eso `__len__` devuelve `N_dias - 15`).

    """

    def __init__(self, entradas, ruido_usado):
        """
        entradas: Tensor [N_dias, 8, 24]
        ruido_usado: float √∫nico que define la escala de ruido a aplicar
        """
        self.entradas = entradas
        self.ruido_usado = ruido_usado

    def __len__(self):
        return self.entradas.shape[0] - (1+14) # Necesitamos 14 d√≠as previos + 1 objetivo

    def __getitem__(self, idx):
        idx = idx + (1+14)  # desplazamos para tener -15:-1 disponibles

        # D√≠a actual
        dia_actual = self.entradas[idx]  # [8, 24]

        #variable de debug, puedo cambiar significativametne los datos para contrastar. A 1 por defecto
        multiplicador = 1

        hora_sin = dia_actual[0].unsqueeze(0)   # [1, 24]
        hora_cos = dia_actual[1].unsqueeze(0)
        dia_sin = dia_actual[2].unsqueeze(0)
        dia_cos = dia_actual[3].unsqueeze(0)
        mes_sin = dia_actual[4].unsqueeze(0)
        mes_cos = dia_actual[5].unsqueeze(0)
        temperatura = dia_actual[6].unsqueeze(0)
        param_a_pred = (dia_actual[7].unsqueeze(0))*multiplicador  # objetivo
        #print(param_a_pred)


        #para generar mas datos y que no se los prenda, meto un ruido ligero
        #ruido = torch.relu((torch.rand_like(param_a_pred)) * 0.001) # ruido en [0, 0.01]
        #ruido = param_a_pred * 0.01 * torch.randn_like(param_a_pred)  # ruido ‚àù valor

        if torch.rand(1).item() < 0.20:  # 20% de las veces
            ruido = param_a_pred * self.ruido_usado * torch.randn_like(param_a_pred)  # ruido ‚àù valor
        else:
            ruido = torch.zeros_like(param_a_pred)





        temperatura_ruidosa = temperatura #+ ruido
        param_a_pred_ruidoso =  torch.relu(param_a_pred + ruido) #relu para quitar posibles negativos
        #print(param_a_pred_ruidoso)

        canales_dia_actual = torch.cat([dia_sin, dia_cos, hora_sin, hora_cos, mes_sin, mes_cos, temperatura_ruidosa], dim=0)  # [7, 24]


        # Hist√≥rico: d√≠as previos (sin el d√≠a actual)
        historico_completo = self.entradas[idx - 15:idx - 1]  # [14, 8, 24]
        # OJO: cambiamos orden a [6, 7, 24] para que el modelo lo lea como canales √ó d√≠as √ó horas
        historico_ordenado = historico_completo.permute(1, 0, 2)  # [8, 14, 24]

        # Aplicar el mismo ruido a la temperatura del hist√≥rico (canal 4) y al historicos historico (canal 5)
        #historico_ordenado[4] += ruido  # temperatura
        historico_ordenado[7] = torch.relu(historico_ordenado[7] + ruido) # demanda o la variable que le pasemos, y relu para mayor a 0 siempre

        # Objetivo: demanda real del d√≠a actual
        objetivo = param_a_pred_ruidoso.squeeze(0)  # [24]

        return {
            "actuales": canales_dia_actual,  # [7, 24]
            "historico": historico_ordenado  # [8, 14, 24]
        }, objetivo


class ResidualBlock1D(nn.Module):
    """
    Bloque residual simple para series temporales 1D.

    Aplica dos capas Conv1D con normalizaci√≥n por lotes y ReLU, y suma la entrada original al final (skip connection).
    √ötil para permitir redes m√°s profundas sin que se degrade el aprendizaje.

    Par√°metros:
    ----------
    channels : int
        N√∫mero de canales (features) de entrada y salida. Se mantiene constante en el bloque.
    """
    def __init__(self, channels):
        super().__init__()
        self.conv1 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm1d(channels)
        self.conv2 = nn.Conv1d(channels, channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm1d(channels)
        self.act = nn.ReLU()

    def forward(self, x):
        identity = x
        out = self.act(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        return self.act(out + identity)



class DualInputForecastNet(nn.Module):
    """
    \nRed neuronal convolucional h√≠brida de doble input dise√±ada para predicci√≥n de series temporales horarias (24 pasos de tiempo por d√≠a), a partir de inputs multicanal diarios y un hist√≥rico multicanal de 14 d√≠as.

    \nArquitectura basada en doble entrada ("Dual Input"):
    1) **Entrada actual (d√≠a objetivo):**
    Tensor de tama√±o `[batch, 7, 24]` que contiene las variables conocidas del d√≠a actual, excluyendo la variable objetivo (se usar√° para evaluaci√≥n pero no se pasa como input). Incluye codificaciones temporales (d√≠a, hora, mes, etc.) y otros inputs como temperatura.

    2) **Hist√≥rico (14 d√≠as previos):**
    Tensor de tama√±o `[batch, 8, 14, 24]` que contiene las mismas variables del d√≠a actual pero extendidas a los 14 d√≠as previos, incluyendo tambi√©n la variable objetivo hist√≥rica (por eso tiene 8 canales frente a los 7 del d√≠a actual, conociendo el historial predigo presente/futuro).

    ---

    \n**Flujo interno de la red:**

    - **Rama Actual (`actuales`):**
        - Dos convoluciones 1D seguidas de batch norm y activaci√≥n ReLU.
        - Un bloque residual (`ResidualBlock1D`) que mejora el flujo de gradiente en entrenamiento profundo.

    - **Rama Hist√≥rico (`historico`):**
        - Tres convoluciones 2D con batch norm y ReLU, operando sobre las dimensiones [canales √ó d√≠as √ó horas].
        - Reducci√≥n de la dimensi√≥n "d√≠as" mediante `.mean(dim=2)`. Condensa el hist√≥rico completo a un tensor de tama√±o `[batch, hidden_dim, 24]`.

    - **Fusi√≥n y salida:**
        - Concatenaci√≥n de ambas ramas a lo largo de la dimensi√≥n de canales, tensor `[batch, 2√óhidden_dim, 24]` (hiddendim x2 por que sumo el ancho de las 2 entradas, act e hist).
        - Dropout para regularizaci√≥n y evitar overfitting.
        - Dos capas finales convolucionales 1D:
            - Primera: expansi√≥n a `hidden_dim` con batch norm y ReLU.
            - Segunda: proyecci√≥n final a un canal de salida, `[batch, 1, 24]`.
        - Se aplica una ReLU final para evitar predicciones negativas (√∫til cuando el target es energ√≠a, demanda, etc.).

    ---

    \n**Par√°metros de inicializaci√≥n:**
    - `hidden_dim` : int_ N√∫mero de canales ocultos internos. Por defecto 256.

    ---

    \n**Forward Input esperado:**
    - Diccionario Python con dos claves:
        - `"actuales"`: Tensor `[batch, 7, 24]`
        - `"historico"` ‚Üí Tensor `[batch, 8, 14, 24]`

    ---

    \n**Output:**
    - Tensor `[batch, 24]`: para las 24 horas del d√≠a objetivo.

    ---

    \n**Notas de implementaci√≥n:**
    - La red est√° optimizada para tareas de forecasting de variables como demanda el√©ctrica, solar o precio.
    - El hist√≥rico pasa por convoluciones 2D para aprovechar el contexto inter-d√≠a, mientras que el d√≠a actual va por convoluciones 1D (secuencias horarias).
    - El bloque residual en la rama actual permite mejorar la capacidad de aprendizaje sin degradaci√≥n por profundidad.
    - El `.mean(dim=2)` condensa de forma simple el hist√≥rico, pero podr√≠as explorar atenciones o RNNs si quisieras una fusi√≥n m√°s compleja.
    - La capa final est√° pensada para trabajar a nivel de hora: 24 outputs independientes por batch.

    """
    def __init__(self, hidden_dim=256):
        super().__init__()
        self.act = nn.ReLU()

        # Datos actuales [B, 5, 24]
        self.conv_actual_1 = nn.Conv1d(7, hidden_dim, kernel_size=3, padding=1)
        self.bn_actual_1 = nn.BatchNorm1d(hidden_dim)

        self.conv_actual_2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)
        self.bn_actual_2 = nn.BatchNorm1d(hidden_dim)

        self.residual_actual = ResidualBlock1D(hidden_dim)

        # Hist√≥rico [B, 6, 7, 24]
        self.conv_hist_1 = nn.Conv2d(8, hidden_dim, kernel_size=(3, 3), padding=1)
        self.bn_hist_1 = nn.BatchNorm2d(hidden_dim)

        self.conv_hist_2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=(3, 3), padding=1)
        self.bn_hist_2 = nn.BatchNorm2d(hidden_dim)

        self.conv_hist_3 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=(3, 3), padding=1)
        self.bn_hist_3 = nn.BatchNorm2d(hidden_dim)

        # Fusi√≥n y salida
        self.dropout = nn.Dropout(0.2)
        #self.final_conv = nn.Conv1d(2 * hidden_dim, 1, kernel_size=3, padding=1)
        self.final_conv1 = nn.Conv1d(2 * hidden_dim, hidden_dim, kernel_size=3, padding=1) #capa "final" mas ancha
        self.final_bn = nn.BatchNorm1d(hidden_dim)
        self.final_out = nn.Conv1d(hidden_dim, 1, kernel_size=3, padding=1)  #la final final parte de la "final" anterior

    def forward(self, entrada):
        actuales = entrada["actuales"]      # [B, 7, 24]
        historico = entrada["historico"]    # [B, 8, 14, 24]

        # Actual
        x_actual = self.act(self.bn_actual_1(self.conv_actual_1(actuales)))   # [B, H, 24]
        x_actual = self.act(self.bn_actual_2(self.conv_actual_2(x_actual)))   # [B, H, 24]
        x_actual = self.residual_actual(x_actual)                             # [B, H, 24]

        # Hist√≥rico
        x_hist = self.act(self.bn_hist_1(self.conv_hist_1(historico)))        # [B, H, 14, 24]
        x_hist = self.act(self.bn_hist_2(self.conv_hist_2(x_hist)))           # [B, H, 14, 24]
        x_hist = self.act(self.bn_hist_3(self.conv_hist_3(x_hist)))           # [B, H, 14, 24]
        x_hist = x_hist.mean(dim=2)                                           # [B, H, 24]

        # Fusi√≥n
        fusionado = torch.cat([x_actual, x_hist], dim=1)                      # [B, 2H, 24]
        fusionado = self.dropout(fusionado)

        #salida = self.final_conv(fusionado)  # [B, 1, 24]
        x = self.act(self.final_bn(self.final_conv1(fusionado)))
        salida = self.final_out(x)

        return torch.relu(salida.squeeze(1))  # Relu para evitar predicciones negativas. [B, 24]




def preparar_datos_para_training(df, secuencia=24, key_historicos="Demanda",dia_inicio=None, dia_fin=None):
    """
    \nPreprocesa un DataFrame de series temporales (normalmente demanda, solar o precio) para generar un tensor listo para ser usado en el Dataset `ForecastSingleFeatureDataset`.

    \nConvierte cada d√≠a (con sus 24 horas) en un bloque multicanal con variables normalizadas y codificadas c√≠clicamente (hora, d√≠a de la semana, mes).
Adem√°s devuelve el factor de ruido usado para el tipo de variable objetivo, que luego se usar√° en el dataset durante el entrenamiento.

    ---

    \n**Flujo:**
    1) Filtra el DataFrame por rango de d√≠as (`dia_inicio`, `dia_fin`) si estos par√°metros se indican.
    2) Calcula codificaciones c√≠clicas para la hora, el dia y el mes, cada uno con un par de seny y coseno.
    3) Normaliza la temperatura al rango `[0, 1]`.
    4) Agrupa los datos en bloques diarios de 24 horas.
    5) Para cada d√≠a completo, construye un tensor de tama√±o `[8, 24]`, donde cada canal corresponde a:
        - Canal 0: Hora_sin
        - Canal 1: Hora_cos
        - Canal 2: Dia_sem_sin
        - Canal 3: Dia_sem_cos
        - Canal 4: Mes_sin
        - Canal 5: Mes_cos
        - Canal 6: Temperatura normalizada
        - Canal 7: Variable objetivo (`key_historicos`), como demanda, solar o precio

    ---

    \n**Control de ruido:**
    - Seg√∫n el valor de `key_historicos`, define un nivel de ruido recomendado:
        - Si es `"PotenciaSolar"`: Ruido muy bajo (`0.0001`)
        - Para el resto: Ruido est√°ndar (`0.001`)
    Dichos valores se han decidido a base de prueba y error y experiencia en el modelo usado
    Este valor se usar√° m√°s adelante en el dataset para aplicar ruido a la salida y al hist√≥rico.

    ---

    \n**Par√°metros:**
    - `df` : pd.DataFrame, DataFrame original, ya con columna `"DATE"` y todas las variables necesarias.
    - `secuencia` : int (default=24), N√∫mero de pasos por d√≠a. Generalmente 24 para datos horarios.
    - `key_historicos` : str, Nombre de la columna del DataFrame que contiene la variable objetivo (demanda, solar o precio).
    - `dia_inicio`, `dia_fin` : int or None, Filtrado opcional por rango de d√≠as num√©ricos (`Dia_int`). Si no se indica, se usan todos los d√≠as disponibles.

    ---

    \n**Returns:**
    - `entradas` : torch.Tensor, Tensor de tama√±o `[N_dias, 8, 24]`, donde `N_dias` es el n√∫mero de d√≠as completos disponibles (aqui ya va predicho el valor).
    - `ruido_usado` : float, Escala de ruido a aplicar durante el entrenamiento.
    ---

    \n**Notas:**
    - La funci√≥n asume que el DataFrame ya tiene columnas: `"DATE"`, `"Hora_int"`, `"Dia_sem"`, `"Mes"`, `"Temperatura"`, y la variable especificada en `key_historicos`.
    - Si no se encuentran d√≠as completos (24h por d√≠a), la funci√≥n lanza un error.
    - La estructura de salida est√° espec√≠ficamente dise√±ada para alimentar el dataset `ForecastSingleFeatureDataset`.

    """

    # Define intensidad de ruido por tipo de variable
    if key_historicos == "PotenciaSolar":
        ruido_usado = 0.0001
    else:
        ruido_usado = 0.001  # por defecto

    df_proc = df.copy()
    if dia_inicio and dia_fin:
        df_proc = df_proc[(df_proc['Dia_int'] >= dia_inicio) & (df_proc['Dia_int'] <= dia_fin)]

    # Transformaciones c√≠clicas
    df_proc["Dia_sem_sin"] = np.sin(2 * np.pi * df_proc["Dia_sem"] / 7)
    df_proc["Dia_sem_cos"] = np.cos(2 * np.pi * df_proc["Dia_sem"] / 7)

    df_proc["Hora_sin"] = np.sin(2 * np.pi * df_proc["Hora_int"] / 24)
    df_proc["Hora_cos"] = np.cos(2 * np.pi * df_proc["Hora_int"] / 24)

    df_proc["Mes_sin"] = np.sin(2 * np.pi * df_proc["Mes"] / 12)
    df_proc["Mes_cos"] = np.cos(2 * np.pi * df_proc["Mes"] / 12)


    # Normalizar temperatura
    temp_min = df_proc["Temperatura"].min()
    temp_max = df_proc["Temperatura"].max()
    df_proc["Temperatura_norm"] = (df_proc["Temperatura"] - temp_min) / (temp_max - temp_min)

    entradas = []
    ids_tipo = [] #para el ruido

    #voy a agrupar por 24 (24 horas, 1 dia), genera una matriz de filas columnas y dias (3d)
    for fecha, grupo in df_proc.groupby("DATE"):
        if len(grupo) < secuencia:
            continue

        hora_sin = torch.tensor(grupo["Hora_sin"].values[:secuencia], dtype=torch.float32)
        hora_cos = torch.tensor(grupo["Hora_cos"].values[:secuencia], dtype=torch.float32)

        dia_sem_sin = torch.tensor(grupo["Dia_sem_sin"].values[:secuencia], dtype=torch.float32)
        dia_sem_cos = torch.tensor(grupo["Dia_sem_cos"].values[:secuencia], dtype=torch.float32)

        mes_sin = torch.tensor(grupo["Mes_sin"].values[:secuencia], dtype=torch.float32)
        mes_cos = torch.tensor(grupo["Mes_cos"].values[:secuencia], dtype=torch.float32)

        temperatura = torch.tensor(grupo["Temperatura_norm"].values[:secuencia], dtype=torch.float32)
        historico = torch.tensor(grupo[key_historicos].values[:secuencia], dtype=torch.float32)

        entrada = torch.stack([hora_sin, hora_cos, dia_sem_sin, dia_sem_cos, mes_sin, mes_cos, temperatura, historico], dim=0)  # [6, 24]
        entradas.append(entrada)

    if len(entradas) == 0:
        raise ValueError("No se encontraron d√≠as con datos completos para entrenamiento.")

    return torch.stack(entradas), ruido_usado  # [N_dias, 6, 24], 1

def preparar_datos_para_predecir_real(df, secuencia=24, key_historicos="Demanda",dia_inicio=None, dia_fin=None):
    """
    \nPreprocesa un DataFrame de series temporales (demanda, solar o precio) para crear un tensor listo para predicci√≥n real con el modelo `DualInputForecastNet`.
    A diferencia de `preparar_datos_para_training`, aqu√≠ **no se a√±ade ruido** y se conserva la secuencia real de la variable objetivo (sin modificar).

    ---

    \n**Objetivo:**
    - Convertir el DataFrame de entrada en un tensor `[N_dias, 8, 24]` apto para pasarlo al Dataset (`ForecastSingleFeatureDataset`) y hacer predicciones reales.
    - Devolver tambi√©n un vector con las fechas efectivas que el modelo va a predecir (teniendo en cuenta los primeros 15 d√≠as de historial).

    ---

    \n**Flujo:**
    1) Filtra el DataFrame por rango de d√≠as (`dia_inicio`, `dia_fin`) si se indican.
    2) Calcula codificaciones c√≠clicas para hora, d√≠a y mes (pares seno/coseno para cada uno).
    3) Normaliza la temperatura al rango `[0, 1]`.
    4) Agrupa los datos en bloques diarios de 24 horas.
    5) Detecta cu√°les son los d√≠as completos (con 24 horas de datos).
    6) Calcula qu√© d√≠as se van a predecir efectivamente (saltando los primeros 15 d√≠as necesarios de historial).
    7) Genera un tensor `[N_dias, 8, 24]`, donde cada d√≠a contiene:
        - Canal 0: Hora_sin
        - Canal 1: Hora_cos
        - Canal 2: Dia_sem_sin
        - Canal 3: Dia_sem_cos
        - Canal 4: Mes_sin
        - Canal 5: Mes_cos
        - Canal 6: Temperatura normalizada
        - Canal 7: Variable objetivo real (sin ruido, tal como est√° en el DataFrame)

    ---

    \n**Par√°metros:**
    - `df` : pd.DataFrame, DataFrame original, ya con columna `"DATE"` y todas las variables necesarias.
    - `secuencia` : int (default=24), N√∫mero de pasos por d√≠a. Generalmente 24 para datos horarios.
    - `key_historicos` : str, Nombre de la columna del DataFrame que contiene la variable objetivo (ejemplo `"Demanda"`, `"PotenciaSolar"`, `"Precio"`).
    - `dia_inicio`, `dia_fin` : int or None , Filtrado opcional por rango de d√≠as (`Dia_int`). Si no se indican, usa todos los d√≠as disponibles.

    ---

    \n**Returns:**
    - `entradas` : torch.Tensor, Tensor de tama√±o `[N_dias, 8, 24]`, donde `N_dias` es el n√∫mero de d√≠as completos.
    - `ruido_usado` : float, Valor fijo `0`, ya que aqu√≠ no se aplica ruido (predicci√≥n real, no entrenamiento).

    ---

    \n**Notas:**
    - Se asegura que s√≥lo se incluyan d√≠as completos (24h), y s√≥lo predice a partir del d√≠a 16 en adelante (por necesidad de historial de 15 d√≠as).
    - Estructura de salida dise√±ada para alimentar directamente al Dataset y luego al modelo.
    - No altera la variable objetivo, no a√±ade ruido, no hay data augmentation. Es para evaluaci√≥n o predicci√≥n sobre datos reales.
    - Si no hay d√≠as suficientes, lanza un error.
    """

    ruido_usado = 0

    df_proc = df.copy()
    if dia_inicio and dia_fin:
        df_proc = df_proc[(df_proc['Dia_int'] >= dia_inicio) & (df_proc['Dia_int'] <= dia_fin)]
        #print("test proc")
        #print(df_proc)
        #print(df_proc.to_string())

    conteo_por_fecha = df_proc.groupby("DATE").size()
    #print("Filas por cada DATE en df_proc:")
    #print(conteo_por_fecha.to_string())

    # D√≠as que tienen exactamente 24 filas:
    dias_completos = [d for d, cnt in conteo_por_fecha.items() if cnt == 24]
    #print("D√≠as completos en df_proc:", dias_completos)

    # D√≠as que realmente el Dataset terminar√° prediciendo (saltando los primeros 15)
    dias_que_modelo_predice = dias_completos[15:]
    #print("Despu√©s de los 15 d√≠as de historial, el modelo predice estos d√≠as:", dias_que_modelo_predice)

    # Transformaciones c√≠clicas
    df_proc["Dia_sem_sin"] = np.sin(2 * np.pi * df_proc["Dia_sem"] / 7)
    df_proc["Dia_sem_cos"] = np.cos(2 * np.pi * df_proc["Dia_sem"] / 7)

    df_proc["Hora_sin"] = np.sin(2 * np.pi * df_proc["Hora_int"] / 24)
    df_proc["Hora_cos"] = np.cos(2 * np.pi * df_proc["Hora_int"] / 24)

    df_proc["Mes_sin"] = np.sin(2 * np.pi * df_proc["Mes"] / 12)
    df_proc["Mes_cos"] = np.cos(2 * np.pi * df_proc["Mes"] / 12)


    # Normalizar temperatura
    temp_min = df_proc["Temperatura"].min()
    temp_max = df_proc["Temperatura"].max()
    df_proc["Temperatura_norm"] = (df_proc["Temperatura"] - temp_min) / (temp_max - temp_min)

    entradas = []
    ids_tipo = [] #para el ruido

    #voy a agrupar por 24 (24 horas, 1 dia), genera una matriz de filas columnas y dias (3d)
    for fecha, grupo in df_proc.groupby("DATE"):
        if len(grupo) < secuencia:
            continue

        hora_sin = torch.tensor(grupo["Hora_sin"].values[:secuencia], dtype=torch.float32)
        hora_cos = torch.tensor(grupo["Hora_cos"].values[:secuencia], dtype=torch.float32)

        dia_sem_sin = torch.tensor(grupo["Dia_sem_sin"].values[:secuencia], dtype=torch.float32)
        dia_sem_cos = torch.tensor(grupo["Dia_sem_cos"].values[:secuencia], dtype=torch.float32)

        mes_sin = torch.tensor(grupo["Mes_sin"].values[:secuencia], dtype=torch.float32)
        mes_cos = torch.tensor(grupo["Mes_cos"].values[:secuencia], dtype=torch.float32)

        temperatura = torch.tensor(grupo["Temperatura_norm"].values[:secuencia], dtype=torch.float32)
        historico = torch.tensor(grupo[key_historicos].values[:secuencia], dtype=torch.float32)

        entrada = torch.stack([hora_sin, hora_cos, dia_sem_sin, dia_sem_cos, mes_sin, mes_cos, temperatura, historico], dim=0)  # [6, 24]
        entradas.append(entrada)

    if len(entradas) == 0:
        raise ValueError("No se encontraron d√≠as con datos completos para entrenamiento.")

    return torch.stack(entradas), ruido_usado  # [N_dias, 6, 24], 1



def entrenar_dual_input(datos_dataset, ruido_usado,epochs=10000,lr=1e-3,device="cuda",ruta_modelo=None):
    """
    \nFunci√≥n principal de entrenamiento para el modelo `DualInputForecastNet` en una tarea de prediccion horario (produce sets 24 valores, 1 dia, 24h).
Entrena el modelo a partir de un dataset de d√≠as hist√≥ricos (`ForecastSingleFeatureDataset`), y para las condiciones y resticciones (loss) es capaz de aceptar
condiciones asimetricas y ponderadas por horas para ajustar el entrenamiento y afinar el resultado al deseado.

    \nSin embargo estas condiciones y etre entrenamiento debe hacerse semimanualmente, ajustandole los coeficientes de error
antes de cada entrenamiento, ir viendo donde se equivoca mas, que zonas son criticas y hacer que la IA ajuste mejor esas zonas.

    \nUn comportamiento que se ha observado de esta red neuronal es que tiede a "no arriesgar", es decir, tiende a no dar valores picos altos,
asi que debe ajustarse una asimetria en los aprametros de eror (loss) para no castigar tan duramente estos picos altos aun cuando se equivoque.
Ademas se puede ponderar algunas horas para poder hacer que se centre mas en los rangos horarios deseados, principalmente las horas picos, las mas importantes

    ---
    \n**Flujo de entrenamiento:**
    1) Crea un DataLoader sobre el dataset de entrenamiento.
    2) Inicializa el modelo y el optimizador Adam.
    3) Si se especifica `ruta_modelo` y el archivo existe, carga el modelo y el optimizador desde esa ruta (permite continuar entrenamientos previos).
    4) Define una funci√≥n de p√©rdida personalizada, (y de configuracion manual en el codigo `loss_ponderada_asimetrica`) que:
       - Aplica mayor penalizaci√≥n a errores negativos (cuando el modelo predice menos de lo que deb√≠a).
       - Permite dar m√°s peso a ciertas horas del d√≠a (mediante el vector `pesos_por_hora`).
    5) Realiza el bucle de entrenamiento:
       - Para cada epoch, recorre el DataLoader.
       - Calcula la salida del modelo.
       - Aplica la funci√≥n de p√©rdida.
       - Incluye una penalizaci√≥n adicional si el modelo genera valores negativos (asimetria).
       - Actualiza pesos mediante retropropagaci√≥n.
       - Muestra logs cada `imprimir_cada` epochs.
       - Guarda checkpoints cada `guardar_cada` epochs en una carpeta espec√≠fica.

    ---
    \n**Detalles clave del sistema de p√©rdidas:**
    - El criterio principal es una variante del MSE (Mean Squared Error), pero:
       - **Asim√©trico:** Penaliza m√°s fuerte los errores por defecto (cuando la predicci√≥n es menor que el real) usando un vector `penal_negativa` mayor que `penal_positiva`.
       - **Ponderado por hora:** Algunas horas tienen mayor importancia (por ejemplo, horas punta).

    ---
    \n**Par√°metros:**
    - `datos_dataset` : torch.Tensor, tensor de entrada de tama√±o `[N_dias, 8, 24]`, generado previamente con `preparar_datos_para_training`.
    - `ruido_usado` : float, escala del ruido usado por el dataset (pasa directo a `ForecastSingleFeatureDataset`).
    - `epochs` : int (default=10000), N√∫mero de √©pocas de entrenamiento, aka veces que entrena. Referencia, en una 5070ti tarda aproximadamente 60s cada 1000 epochs.
    - `lr` : float (default=1e-3), Learning rate del optimizador Adam. Mas alto mas rapido pero mas inestable, mas bajo mas lento pero mas estable.
    - `device` : str (default=`"cuda"`), dispositivo donde entrenar el modelo (`"cuda"` o `"cpu"`). Altamente desaconsejado entrenar el modelo en cpu (es posible usar en cpu, pero no entrenar).
    - `ruta_modelo` : str o None, Ruta a un checkpoint previo para reanudar el entrenamiento (si existe). Si no se indica, se entrena desde cero.

    ---
    \n**Returns:**
    - `modelo` : DualInputForecastNet, modelo entrenado.
    - `optimizador` : torch.optim.Optimizer, estado final del optimizador (por si se quiere guardar o continuar despu√©s).

    ---
    \n**Notas:**
    - El tama√±o de batch (`2048`), el n√∫mero de workers (`8`) y la pol√≠tica de persistencia est√°n ajustados para m√°quinas
    con decente RAM y GPU (referencia nvidia 5070ti de 16 gb). Se pueden ajustar si es necesario.
    - Los checkpoints se guardan bajo la carpeta `"DatosIA/quicksaves_modelo_<nombre_modelo>"`. Esta pensado para guardar un "quicksave"
    cada 10k epochs (aprox cada 10m en mi hardware). Sirve para un guardado para no pede el progreso en caso de que algo ocurra,
    o para poder elegir un modelo distinto al final (posible caso de overfitting a epochs mas altas, con el debug por consola se puede ver el loss,
    mientras entrena y se puede ver que loss tiene cada modelo guardado y estimar cual es el mas conveniente y confirmar luego de una evaluacion)
    - El c√≥digo incluye control para detectar y romper el entrenamiento si aparecen NaN o Inf en la p√©rdida, por seguridad, y ademas gaurda para no peerder el progreso.
    """

    batch_size = 2048
    dataset = ForecastSingleFeatureDataset(datos_dataset, ruido_usado)
    loader = DataLoader(dataset,batch_size=batch_size,shuffle=True,num_workers=8,pin_memory=True,persistent_workers=True)

    modelo = DualInputForecastNet().to(device)
    optimizador = torch.optim.Adam(modelo.parameters(), lr=lr)

    # Cargar modelo si se especifica ruta
    if ruta_modelo and os.path.exists(ruta_modelo):
        checkpoint = torch.load(ruta_modelo, map_location=device)
        modelo.load_state_dict(checkpoint["modelo"])
        optimizador.load_state_dict(checkpoint["optimizador"])
        print(f"Modelo y optimizador cargados desde {ruta_modelo}")

    #criterio = nn.MSELoss(reduction='sum')   # suma los errores
    imprimir_cada = 1000 #numero de epochs cada que imprime en consola
    guardar_cada = 10000 #numero de epochs cada que guarda un "quicksave"




    #=== CONDICIONES ===

    #me creo un criterio de MSE pero penalizando mas algunas horas concretas. Ademas penalizo mas el quedarse corto que el no pasarse, tiende a eso el modelo
    #se pueden incluir y comentar y descomentar las lineas de pesos de condiciones que sean necesarios
    pesos_por_hora = torch.tensor([1.0] * 24, device=device)
    #pesos_por_hora[20:24] = 1 # 18 a 22 incluidos
    #pesos_por_hora[7:12] = 2.5  # 12 a 15 incluidos
    #penal_positiva = 1
    #penal_negativa = 3 #penalizo mas el negativo
    penal_positiva = torch.tensor([1.0] * 24, device=device)
    penal_positiva[17:20] = 1.5
    penal_negativa = torch.tensor([1.0] * 24, device=device)
    penal_negativa[20:23] = 3

    def loss_ponderada_asimetrica(salida, objetivos):
        multiplicador_perdida_mse = 2 #multiplicador general de la perdida

        error = salida - objetivos  # [B, 24]
        errores_cuadrado = error ** 2   # **2 es elevado a 2, cuadrado, (MSE)

        penalizacion = torch.where(error < 0, penal_negativa, penal_positiva)  # [B, 24]. La parte asimetrica

        ponderado = errores_cuadrado * penalizacion * pesos_por_hora  # broadcasting [24]. aqui uso las penalizaciones desiguales y la asimetria

        loss_mse = ponderado.sum() #ponderado es un vector, los sumo. Otra opcion podria hacer una media o una mediana. Opto por suma
        loss_total = loss_mse * multiplicador_perdida_mse

        return loss_total

    #=== FIN CONDICIONES ===



    print("Iniciando entrenamiento...")
    start_time = time.time()
    start_time_acum = time.time()



    #=== ENTRENAMIENTO DE LA EPOCH ===

    ciclo_entreno_roto = False
    for epoch in range(epochs):
        modelo.train()
        #perdidas = []
        #perdidas_mse = []
        #perdidas_penal = []

        for entrada, objetivos in loader:
            # Mover cada componente al dispositivo
            # el dataset genera el doble input con los datos horarios y el dato de hoy. Tienen dimensiones distintas, no compatibles en el mismo input
            entrada_device = {
                "actuales": entrada["actuales"].to(device),
                "historico": entrada["historico"].to(device)
            }

            #PREDICCION
            objetivos = objetivos.to(device)
            salida = modelo(entrada_device)  # [B, 24]

            #calculo la loss de esta prediccion
            loss_total = loss_ponderada_asimetrica(salida, objetivos)

            #if para si se ha roto pues prepara para salir
            if torch.isnan(loss_total) or torch.isinf(loss_total):
                print("üî• NaN detectado. Debug info:")
                print(f"Salida max abs: {salida.abs().max().item()}")
                ciclo_entreno_roto = True
                break

            #aplico penalizaciones y actualizo gradiente del optimizador de la red
            optimizador.zero_grad()
            loss_total.backward()
            optimizador.step()

            #perdidas.append(loss_total.detach().item())
            #perdidas_mse.append(loss_mse.detach().item())
            #perdidas_penal.append(penalizacion_negativos.detach().item())

        #si se ha roto sal del bucle
        if ciclo_entreno_roto:
            break

        #imprimir debug en consola
        if (epoch + 1) % imprimir_cada == 0:
            duracion = time.time() - start_time
            duracion_acum = time.time() - start_time_acum
            start_time = time.time()

            #print(f"Epoch {epoch + 1}/{epochs} - Loss total: {loss_total.detach().item():.8f} (MSE: {lambda_penal_mse * loss_mse.detach().item():.6f}, Negativos: {lambda_penal_neg * penalizacion_negativos.detach().item():.6f}) - Tiempo: {duracion:.2f}s (Acum: {duracion_acum:.2f}s)")
            print(f"Epoch {epoch + 1}/{epochs} - Loss total: {loss_total.detach().item():.8f} - Tiempo: {duracion:.2f}s (Acum: {duracion_acum:.2f}s)")

        #guarda el modelo "quicksave", ambos modelo en si como el estado del optimizador para poder seguir por donde iba
        if (epoch + 1) % guardar_cada == 0:
            nombre_base = os.path.splitext(os.path.basename(ruta_modelo))[0]
            ruta_carpeta_ia = "DatosIA"
            ruta_quicksave_dir = os.path.join(ruta_carpeta_ia, f"quicksaves_modelo_{nombre_base}")
            os.makedirs(ruta_quicksave_dir, exist_ok=True)

            ruta_quicksave = os.path.join(ruta_quicksave_dir, f"modelo_epoch{epoch + 1}.pt")
            torch.save({
                "modelo": modelo.state_dict(),
                "optimizador": optimizador.state_dict()
            }, ruta_quicksave)
            print(f"Checkpoint guardado en {ruta_quicksave}")

    return modelo, optimizador



def evaluar_modelo_con_df(nombre_modelo, datos_df, key_objetivo, dia_inicio=None, dia_fin=None, device="cuda"):
    """
    Eval√∫a un modelo `DualInputForecastNet` sobre un DataFrame de entrada, devolviendo las predicciones de la IA y los valores reales para los d√≠as indicados.
    Funcion de evaluacion, mantiene el ruido para que el modelo y la real partan del los mismos datos, con el ruido

    ---
    \n**Flujo:**
    1) Carga el modelo desde la carpeta `"DatosIA/"`, usando `nombre_modelo`. Admite checkpoints guardados con o sin clave `"modelo"` (por la forma en la que guardo el modelo).
    2) Prepara los datos usando `preparar_datos_para_training()`, incluyendo autom√°ticamente 14 d√≠as de historial antes de `dia_inicio` (necesario para la entrada del modelo).
    3) Crea un DataLoader y ejecuta la inferencia por lotes (`torch.no_grad()`), sin c√°lculo de gradientes.
    4) Devuelve dos tensores:
       - Predicci√≥n de la IA (`[N_dias, 24]`).
       - Datos reales (`[N_dias, 24]`).

    ---
    \n**Par√°metros:**
    - `nombre_modelo` : str, Nombre del archivo dentro de `"DatosIA/"`.
    - `datos_df` : pd.DataFrame, DataFrame con todas las columnas necesarias (igual que en training).
    - `key_objetivo` : str, Nombre de la variable objetivo (ej. `"Demanda"`).
    - `dia_inicio`, `dia_fin` : int o None, Rango de d√≠as a evaluar (`Dia_int`).
    - `device` : str, `"cuda"` o `"cpu"`. La evaluacion es factible hacerla en cpu, pero se recomienda cuda

    ---
    \n**Returns:**
    - `salida_ia` : torch.Tensor `[N_dias, 24]`
    - `salida_real` : torch.Tensor `[N_dias, 24]`
    """

    #parte directamente desde la carpeta de la IA
    ruta_carpeta_ia = "DatosIA"
    ruta_modelo = ruta_carpeta_ia + "/" + nombre_modelo

    # Cargar modelo
    if not os.path.exists(ruta_modelo):
        raise FileNotFoundError(f"El archivo de modelo no existe en la ruta: {ruta_modelo}")

    checkpoint = torch.load(ruta_modelo, map_location=device)
    modelo = DualInputForecastNet().to(device)

    #for name, param in modelo.named_parameters():
    #    print(name, param.data.abs().mean())  # valor medio absoluto por capa

    #modelo.load_state_dict(checkpoint["modelo"])
    # Intento cargar seg√∫n si tiene clave "modelo" (por la forma en la que guardo, que guardo ambos modelo y optimizador
    if "modelo" in checkpoint:
        modelo.load_state_dict(checkpoint["modelo"])
    else:
        modelo.load_state_dict(checkpoint)

    modelo.eval()

    # Preparar datos
    datos_dataset, ruido_usado = preparar_datos_para_training(datos_df, dia_inicio=dia_inicio-14, dia_fin=dia_fin, key_historicos=key_objetivo)
    dataset = ForecastSingleFeatureDataset(datos_dataset, ruido_usado)
    loader = DataLoader(
        dataset,
        batch_size=2048,
        shuffle=False,
        num_workers=8,
        pin_memory=True
    )

    predicciones = []
    objetivos = []

    #PREDICE Y EVALUA
    with torch.no_grad():
        for entrada, objetivo in loader:
            entrada_device = {
                "actuales": entrada["actuales"].to(device),
                "historico": entrada["historico"].to(device)
            }
            objetivo = objetivo.to(device)

            salida = modelo(entrada_device)
            #print(entrada_device)
            #print(salida)

            predicciones.append(salida.cpu())
            objetivos.append(objetivo.cpu())

    #prepara salidas
    salida_ia = torch.cat(predicciones, dim=0)
    salida_real = torch.cat(objetivos, dim=0)


    #torch.set_printoptions(linewidth=300, edgeitems=5)

    #print("-----")
    #print(key_objetivo)
    #print("IA predicci√≥n (primeros 5 d√≠as):")
    #print(salida_ia[:5])


    #print("Real (primeros 5 d√≠as):")
    #print(salida_real[:5])
    #print("-----")

    #meto un multiplicador de x10 en el dataset, aqui lo cancelo
    return salida_ia, salida_real

def predecir_datos_df(ruta_modelo, datos_df, key_objetivo, dia_inicio=None, dia_fin=None, device="cuda"):
    """
    Ejecuta predicci√≥n real usando un modelo `DualInputForecastNet` cargado desde archivo.
Esta es la prediccion real, no aplico ruido si bien uso las mismas fuciones que meten el ruido.
Ademas no devuelvo el dato real, por que no existe dicho dato aun.

    ---
    \n**Flujo:**
    1) Carga el modelo desde la ruta especificada (`ruta_modelo`). Soporta tanto checkpoints con clave `"modelo"` como sin ella (por la forma en la que guardo el modelo).
    2) Prepara los datos de entrada usando `preparar_datos_para_predecir_real()`, incluyendo el ajuste de los 15 d√≠as de hist√≥rico previos (restando `14 historicos + 1 edge case` d√≠as al inicio).
    3) Crea un DataLoader y ejecuta la inferencia por lotes (`torch.no_grad()`).
    4) Concatena todas las predicciones y devuelve s√≥lo la salida de la IA.

    ---
    \n**Par√°metros:**
    - `ruta_modelo` : str, Ruta completa al archivo `.pt` del modelo.
    - `datos_df` : pd.DataFrame, DataFrame de entrada (con todas las variables necesarias).
    - `key_objetivo` : str, Variable objetivo (por ejemplo `"Demanda"`).
    - `dia_inicio`, `dia_fin` : int o None, Rango de d√≠as (`Dia_int`) a predecir.
    - `device` : str, `"cuda"` o `"cpu"`.

    ---
    \n**Returns:**
    - `salida_ia` : torch.Tensor `[N_dias, 24]` ‚Üí Predicciones generadas por el modelo.
    """

    # Cargar modelo
    if not os.path.exists(ruta_modelo):
        raise FileNotFoundError(f"El archivo de modelo no existe en la ruta: {ruta_modelo}")

    checkpoint = torch.load(ruta_modelo, map_location=device)
    modelo = DualInputForecastNet().to(device)

    #for name, param in modelo.named_parameters():
    #    print(name, param.data.abs().mean())  # valor medio absoluto por capa

    #modelo.load_state_dict(checkpoint["modelo"])
    # Intento cargar seg√∫n si tiene clave "modelo"
    # Intento cargar seg√∫n si tiene clave "modelo" (por la forma en la que guardo, que guardo ambos modelo y optimizador
    if "modelo" in checkpoint:
        modelo.load_state_dict(checkpoint["modelo"])
    else:
        modelo.load_state_dict(checkpoint)

    modelo.eval()

    # Preparar datos
    datos_dataset, ruido_usado = preparar_datos_para_predecir_real(datos_df, dia_inicio=dia_inicio-14-1, dia_fin=dia_fin, key_historicos=key_objetivo)
    dataset = ForecastSingleFeatureDataset(datos_dataset, ruido_usado)
    loader = DataLoader(
        dataset,
        batch_size=2048,
        shuffle=False,
        num_workers=8,
        pin_memory=True
    )

    predicciones = []
    objetivos = []

    #PREDICE Y EVALUA
    with torch.no_grad():
        for entrada, objetivo in loader:
            entrada_device = {
                "actuales": entrada["actuales"].to(device),
                "historico": entrada["historico"].to(device)
            }
            objetivo = objetivo.to(device)

            salida = modelo(entrada_device)
            #print(entrada_device)
            #print(salida)

            predicciones.append(salida.cpu())
            objetivos.append(objetivo.cpu())

    #prepara salidas
    salida_ia = torch.cat(predicciones, dim=0)
    salida_real = torch.cat(objetivos, dim=0) #no hay salida real


    #torch.set_printoptions(linewidth=300, edgeitems=5)

    #print("-----")
    #print(key_objetivo)
    #print("IA predicci√≥n (primeros 5 d√≠as):")
    #print(salida_ia[:5])


    #print("Real (primeros 5 d√≠as):")
    #print(salida_real[:5])
    #print("-----")

    #meto un multiplicador de x10 en el dataset, aqui lo cancelo
    return salida_ia




def plot_dia(demanda_ia, demanda_real, indice_dia=0):
    """
    Grafica la predicci√≥n de la IA frente a la demanda real para un d√≠a concreto.

    \nMuestra dos subgr√°ficos:
    1) Predicci√≥n vs Real por hora.
    2) Error por hora (Real - Predicci√≥n).

    \n**Par√°metros:**
    - demanda_ia : Tensor [N_dias, 24]
    - demanda_real : Tensor [N_dias, 24]
    - indice_dia : int ‚Üí D√≠a a visualizar.
    """

    prediccion = demanda_ia[indice_dia].numpy()
    real = demanda_real[indice_dia].numpy()
    horas = list(range(1, 25))

    plt.figure(figsize=(12, 5))

    # Gr√°fico de predicci√≥n vs real
    plt.subplot(2, 1, 1)
    plt.plot(horas, real, label="Real", marker='o')
    plt.plot(horas, prediccion, label="Predicci√≥n IA", marker='x')
    plt.title(f"Demanda Real vs IA - D√≠a {indice_dia}")
    plt.xlabel("Hora del d√≠a")
    plt.ylabel("Demanda")
    plt.legend()
    plt.grid(True)

    # Gr√°fico de error
    plt.subplot(2, 1, 2)
    plt.plot(horas, real - prediccion, label="Error (Real - Predicci√≥n)", color="red", marker='.')
    plt.axhline(0, color='black', linestyle='--')
    plt.title(f"Error por hora - D√≠a {indice_dia}")
    plt.xlabel("Hora del d√≠a")
    plt.ylabel("Error")
    plt.grid(True)

    plt.tight_layout()
    plt.show()



def plot_multidia(demanda_ia, demanda_real, dias=None, continuar=False, titulo="Plot"):
    """
    Grafica la demanda real, la predicci√≥n IA y el error para varios d√≠as seleccionados.

    \nGenera un gr√°fico con 3 subplots apilados verticalmente:

    1) **Demanda real:**
       Muestra la serie real de demanda por hora para cada d√≠a seleccionado. Cada dia lo recorre con un bucle y lo "aplila" en la misma grafica.
       Cada d√≠a se dibuja con un color diferente de la lista `colores`, en l√≠nea s√≥lida con marcadores tipo 'o'.
    2) **Demanda IA:**
       Muestra la predicci√≥n del modelo para los mismos d√≠as. Cada dia lo recorre con un bucle y lo "aplila" en la misma grafica.
       Se representa con l√≠nea discontinua y marcadores tipo 'x', usando los mismos colores que en el subplot anterior para facilitar la comparaci√≥n visual.
    3) **Error (Real - IA):**
       Dibuja el error por hora, d√≠a por d√≠a. Cada dia lo recorre con un bucle y lo "aplila" en la misma grafica.
       L√≠nea de puntos en el mismo color asignado a cada d√≠a. Incluye una l√≠nea horizontal en cero para referencia.

    ---
    \n**Par√°metros:**
    - `demanda_ia` : Tensor `[N_dias, 24]`, predicciones generadas por la IA.
    - `demanda_real` : Tensor `[N_dias, 24]`, valores reales del dataset.
    - `dias` : lista de int, d√≠as a visualizar (√≠ndices de las filas de los tensores). Si es `None`, grafica todos los d√≠as disponibles.
    - `continuar` : bool, si `True`, permite seguir ejecutando c√≥digo despu√©s de mostrar la gr√°fica (no bloquea con `plt.show()`).
    - `titulo` : str, t√≠tulo general del gr√°fico.

    ---
    \n**Notas:**
    - La selecci√≥n de colores recorre c√≠clicamente la lista `colores` si hay m√°s d√≠as que colores (caso mas usual).
    - Se usa `tight_layout()` para evitar solapamiento entre subplots.
    - El eje X representa las 24 horas del d√≠a (de 1 a 24).
    """

    if dias is None:
        dias = list(range(demanda_ia.shape[0]))  # Mostrar todos los d√≠as si no se especifica

    colores = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray']

    horas = np.arange(1, 25)

    plt.figure(figsize=(14, 6))

    # Subplot 1: Demanda Real
    plt.subplot(3, 1, 1)
    for i, dia in enumerate(dias):
        real = demanda_real[dia].numpy()
        pred = demanda_ia[dia].numpy()
        color = colores[i % len(colores)]
        plt.plot(horas, real, label=f'Real D√≠a {dia}', linestyle='-', marker='o', color=color)
        #plt.plot(horas, pred, label=f'IA D√≠a {dia}', linestyle='--', marker='x', color=color)

    plt.title(titulo)
    plt.xlabel("Hora del d√≠a")
    plt.ylabel("Demanda")
    #plt.legend()
    plt.grid(True)

    # Subplot 2: Demanda IA
    plt.subplot(3, 1, 2)
    for i, dia in enumerate(dias):
        real = demanda_real[dia].numpy()
        pred = demanda_ia[dia].numpy()
        color = colores[i % len(colores)]
        #plt.plot(horas, real, label=f'Real D√≠a {dia}', linestyle='-', marker='o', color=color)
        plt.plot(horas, pred, label=f'IA D√≠a {dia}', linestyle='--', marker='x', color=color)

    plt.title("Demanda Predicci√≥n IA - M√∫ltiples d√≠as")
    plt.xlabel("Hora del d√≠a")
    plt.ylabel("Demanda")
    #plt.legend()
    plt.grid(True)

    # Subplot 3: Error (Real - IA)
    plt.subplot(3, 1, 3)
    for i, dia in enumerate(dias):
        error = demanda_real[dia].numpy() - demanda_ia[dia].numpy()
        color = colores[i % len(colores)]
        plt.plot(horas, error, label=f'Error D√≠a {dia}', marker='.', color=color)

    plt.axhline(0, color='black', linestyle='--')
    plt.title("Error por hora - M√∫ltiples d√≠as")
    plt.xlabel("Hora del d√≠a")
    plt.ylabel("Error")
    #plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show(block= not continuar)


def prediccion_matematica_horaria(df,N_dias, key_historicos="Demanda", dia_inicio=None, dia_fin=None):
    """
    Modelo de regresi√≥n lineal (OLS) para predicci√≥n horaria de demanda el√©ctrica usando historial diario.
Utiliza las demandas y temperaturas de los 3 d√≠as anteriores como variables explicativas para predecir la demanda del d√≠a actual.
Es un modelo similar a los ARIMA que se usan clasicamente en la industria electrica, pero algo mas simple

    ---
    \n**Flujo:**
    1) Filtra el DataFrame por rango de d√≠as si se especifica (`dia_inicio`, `dia_fin`).
    2) Calcula variables rezagadas: demanda y temperatura de los 3 d√≠as previos (`t-1`, `t-2`, `t-3`).
    3) Ajusta un modelo OLS (m√≠nimos cuadrados ordinarios) usando estas variables.
    4) Genera predicciones para los √∫ltimos `N_dias` completos del DataFrame.

    ---
    \n**Par√°metros:**
    - `df` : pd.DataFrame, DataFrame de entrada con columnas `"Demanda"` y `"Temperatura"` ya preparadas.
    - `N_dias` : int, n√∫mero de d√≠as a devolver en el resultado final.
    - `key_historicos` : str, nombre de la columna de la variable objetivo (ej. `"Demanda"`).
    - `dia_inicio`, `dia_fin` : int o None, rango opcional de d√≠as a usar.

    ---
    \n**Returns:**
    - `modelo` : statsmodels.regression.linear_model.RegressionResultsWrapper, modelo OLS ajustado (√∫til para inspecci√≥n de coeficientes, aunque no lo uso en realidad).
    - `demanda_predicha` : torch.Tensor `[N_dias, 24]`, predicci√≥n generada por el modelo.
    - `demanda_real` : torch.Tensor `[N_dias, 24]`, valores reales correspondientes a los d√≠as predichos.

    ---
    \n**Notas:**
    - Las predicciones son muy simples comparadas con el modelo IA, pero sirven como baseline o comparaci√≥n r√°pida, o como sustituto si no hay modelos de IA
    """

    df_proc = df.copy()
    hora_maxima = 24

    # Filtro por d√≠as
    if dia_inicio is not None and dia_fin is not None:
        df_proc = df_proc[(df_proc['Dia_int'] >= dia_inicio) & (df_proc['Dia_int'] <= dia_fin)]

    # Ordenamos por fecha y hora
    df_proc = df_proc.sort_values(by=["DATE", "Hora_int"]).reset_index(drop=True)

    # Creamos variables para modelo
    df_proc["demanda_t-1"] = df_proc[key_historicos].shift(1*24)
    df_proc["temperatura_t-1"] = df_proc["Temperatura"].shift(1*24)
    df_proc["demanda_t-2"] = df_proc[key_historicos].shift(2*24)
    df_proc["temperatura_t-2"] = df_proc["Temperatura"].shift(2*24)
    df_proc["demanda_t-3"] = df_proc[key_historicos].shift(3*24)
    df_proc["temperatura_t-3"] = df_proc["Temperatura"].shift(3*24)
    '''    
    for i in range(1, 2):  # 14 d√≠as previos
        df[f"demanda_t-{i * 24}"] = df["Demanda"].shift(i * 24)
        df[f"temperatura_t-{i * 24}"] = df["Temperatura"].shift(i * 24)
    '''
    df_proc.dropna(inplace=True)

    # Seleccionar todas las columnas que empiezan con 'demanda_t-' o 'temperatura_t-'
    #cols_modelo = [col for col in df_proc.columns if col.startswith("demanda_t-") or col.startswith("temperatura_t-")]

    # Tambi√©n incluir la temperatura actual
    #cols_modelo.append("Temperatura")

    #ESTILO OLS
    X = df_proc[["Temperatura","demanda_t-1", "temperatura_t-1","demanda_t-2", "temperatura_t-2","demanda_t-3", "temperatura_t-3"]]
    X = sm.add_constant(X)
    y = df_proc[key_historicos]

    modelo = sm.OLS(y, X).fit()

    df_proc["prediccion"] = modelo.predict(X)

    ultimos_dias = df_proc.tail(N_dias * 24)
    num_dias = ultimos_dias["DATE"].nunique()
    demanda_real = torch.tensor(ultimos_dias["Demanda"].values).reshape(num_dias, 24)
    demanda_predicha = torch.tensor(ultimos_dias["prediccion"].values).reshape(num_dias, 24)

    return modelo, demanda_predicha, demanda_real

def entrenar_ia(nombre_modelo, key_objetivo, device="cuda", epochs=50000, dia_inicio=1, dia_fin=365):
    """
    Entrena un modelo de IA (red neuronal) para predecir la demanda el√©ctrica horaria a partir de variables hist√≥ricas.

    Usa como entrada un conjunto de datos generados por `preparar_datos_para_training`, que puede incluyen parametros de temperatura (ya obtenidos de web de meteorologia),
demandas de la casa, precios de OMIE e irrdancias solares. Guarda el modelo entrenado y su optimizador en la ruta especificada para uso posterior o reentrenamiento.

    ---
    \n**Flujo:**
    1) Prepara los datos usando `preparar_datos_para_training`, filtrando por d√≠as si se indican (`dia_inicio`, `dia_fin`).
    2) Llama a `entrenar_dual_input`, que entrena una red neuronal con entradas m√∫ltiples (ej. temperatura + ruido).
    3) Guarda el modelo y el optimizador entrenados en disco (`DatosIA/<nombre_modelo>`).

    ---
    \n**Par√°metros:**
    - `nombre_modelo` : str, nombre del archivo donde se guardar√° el modelo entrenado.
    - `key_objetivo` : str, nombre de la variable objetivo (ej. `"Demanda"`).
    - `device` : str, dispositivo de entrenamiento (`"cuda"` o `"cpu"`). Altamente desaconsejable usar la cpu en entrenamiento (en evaluacion es aceptable la cpu)
    - `epochs` : int, n√∫mero de iteraciones de entrenamiento.
    - `dia_inicio`, `dia_fin` : int, l√≠mites opcionales para los d√≠as del dataset usados en el entrenamiento.

    ---
    \n**Returns:**
    - No retorna nada expl√≠citamente, pero guarda el modelo y el optimizador entrenado en disco, en la carpeta `"DatosIA"` con el nombre proporcionado.

    ---
    \n**Notas:**
    - Si el archivo ya existe, el modelo continuar√° entren√°ndose desde el estado anterior.
    """

    ruta_carpeta_ia = "DatosIA"
    ruta_modelo = ruta_carpeta_ia + "/" + nombre_modelo

    print(f"Iniciando entrenamiento - {key_objetivo}")
    # si le paso ruta parto de modelo ya creado y lo sigo entrenado. Si no es uno nuevo
    datos_dataset, ruido_usado = preparar_datos_para_training(datos_emparejados, dia_inicio=dia_inicio, dia_fin=dia_fin, key_historicos=key_objetivo)
    # modelo, optimizador = entrenar_single_feature(datos_dataset, epochs=50000, ruta_modelo=ruta_modelo)
    modelo, optimizador = entrenar_dual_input(datos_dataset, ruido_usado, epochs=epochs, ruta_modelo=ruta_modelo, device=device)

    # Guardar el modelo entrenado en la carpeta principal
    torch.save({
        "modelo": modelo.state_dict(),
        "optimizador": optimizador.state_dict()
    }, ruta_modelo)
    print(f"Modelo guardado en: {ruta_modelo}")



def predecir_modelo_IA(dia_inicio,dia_fin,ruta_modelo,datos_emparejados,objetivo,device="cuda"):
    """
    Aplica un modelo de IA previamente entrenado para generar predicciones horarias sobre una variable objetivo espec√≠fica,
    como el precio de OMIE o la demanda el√©ctrica.

    Utiliza el modelo guardado en `ruta_modelo` y realiza la predicci√≥n sobre los d√≠as indicados. Si hay problemas de alineaci√≥n temporal,
    prueba autom√°ticamente con varios desfases (offsets) hacia atr√°s para encontrar uno v√°lido. Si las dimensiones no coinciden,
    reintenta hasta 16 veces con offsets crecientes.

    ---
    \n**Flujo:**
    1) Intenta generar predicciones sobre el rango [`dia_inicio`, `dia_fin`], ajustando el offset de entrada si es necesario.
    2) Compara las predicciones con los datos reales en el rango objetivo.
    3) Si las dimensiones coinciden, reemplaza los valores reales por las predicciones en la columna de `objetivo`.

    ---
    \n**Par√°metros:**
    - `dia_inicio` : int, d√≠a inicial del periodo a predecir.
    - `dia_fin` : int, d√≠a final del periodo a predecir.
    - `ruta_modelo` : str, ruta al archivo `.pt` del modelo entrenado.
    - `datos_emparejados` : pd.DataFrame, dataset de entrada con todas las features ya preparadas.
    - `objetivo` : str, nombre de la variable a predecir (ej. `"PrecioOMIE"` o `"Demanda"`).
    - `device` : str, dispositivo donde se ejecutar√° el modelo (`"cuda"` o `"cpu"`). En prediccion se recomenda cuda, pero es aceptable la cpu.

    ---
    \n**Returns:**
    - `datos_emparejados` : pd.DataFrame de la entrada de datos con la columna `objetivo` ya modificada con las predicciones generadas por el modelo.

    ---
    \n**Notas:**
    - Se realizan varios intentos con offsets crecientes si la predicci√≥n inicial falla por desajuste de tama√±os. Si ning√∫n
     offset es v√°lido, se omite la predicci√≥n sin lanzar error cr√≠tico.
    - No modifica otras columnas del DataFrame, solo sobreescribe los valores en `objetivo` para los d√≠as indicados. Se puede
    encadenar la salida de uno con la entrada de otro con el mismo df para predecir valores para distntos parametros
    """

    #=== PREDICCI√ìN DE PRECIO ===
    #intenta emparejar los generado con los datos existentes, varios try metiendo offsets
    if dia_inicio is not None and dia_fin is not None:
        for n in range(16):  # probamos con offset = 0 .. 15
            try:
                precio_ia = predecir_datos_df(
                    ruta_modelo,
                    datos_emparejados,
                    objetivo,
                    dia_inicio=dia_inicio - n, #n el offset
                    dia_fin=dia_fin,
                    device=device
                )
                mask_precio = datos_emparejados["Dia_int"].between(dia_inicio, dia_fin)
                filas_precio = datos_emparejados.loc[mask_precio]
                array_vals = precio_ia.flatten().cpu().numpy()

                if len(filas_precio) != len(array_vals):
                    raise ValueError(
                        f"Tama√±o incompatible {objetivo}: {len(filas_precio)} filas vs {len(array_vals)} valores de IA"
                    )

                datos_emparejados.loc[mask_precio, objetivo] = array_vals
                break  # si no da error, salimos del loop, ya quedo empajado correctamente
            except ValueError:
                continue

    print("Finalizada prediccion de precios futuros correctamente.")

    return datos_emparejados

def predecir_modelo_clasico(dia_inicio, dia_fin, datos_emparejados, objetivo):
    """
    Genera una predicci√≥n horaria de una variable objetivo (como demanda o precio) utilizando un modelo de regresi√≥n lineal cl√°sico (OLS),
    basado en los valores de los 3 d√≠as anteriores y las temperaturas correspondientes.

    Este enfoque se inspira en modelos tipo ARIMA pero simplificados, sin estacionalidades ni componentes autorregresivos complejos.
    Es √∫til como baseline r√°pido o como m√©t0do de respaldo cuando no se dispone de un modelo de IA entrenado.

    ---
    \n**Flujo:**
    1) Ordena el DataFrame cronol√≥gicamente y crea variables rezagadas (`t-1`, `t-2`, `t-3`) tanto para la variable objetivo como para la temperatura.
    2) Ajusta un modelo OLS usando estas variables explicativas.
    3) Calcula la predicci√≥n y reemplaza los valores de la columna `objetivo` para los d√≠as entre `dia_inicio` y `dia_fin`.

    ---
    \n**Par√°metros:**
    - `dia_inicio` : int, d√≠a inicial del periodo a predecir.
    - `dia_fin` : int, d√≠a final del periodo a predecir.
    - `datos_emparejados` : pd.DataFrame, dataset completo que incluye la variable objetivo y `"Temperatura"`.
    - `objetivo` : str, nombre de la variable a predecir (ej. `"Demanda"` o `"PrecioOMIE"`).

    ---
    \n**Returns:**
    - `df_proc` : pd.DataFrame, copia modificada del DataFrame original con la columna `objetivo` reemplazada por la predicci√≥n generada
      en el rango de d√≠as especificado.

    ---
    \n**Notas:**
    - El modelo usa como entrada las variables rezagadas: `objetivo_t-1`, `t-2`, `t-3` y sus temperaturas correspondientes.
    - El modelo es completamente determinista y no requiere entrenamiento externo.
    - Si el n√∫mero de filas a predecir no coincide con el n√∫mero de valores generados, lanza un error cr√≠tico.
    - Las predicciones reemplazan los valores de `objetivo` **solo** en el rango de d√≠as especificado. El resto no lo modifica
    y devuelve, puede ser usado la salida como entrada propia para otro parametro
    """

    df_proc = datos_emparejados.copy()
    hora_maxima = 24

    # Filtro por d√≠as
    #df_proc = df_proc[(df_proc['Dia_int'] >= dia_inicio) & (df_proc['Dia_int'] <= dia_fin)]

    # Ordenamos por fecha y hora
    df_proc = df_proc.sort_values(by=["DATE", "Hora_int"]).reset_index(drop=True)

    # Creamos variables para modelo
    df_proc["objetivo_t-1"] = df_proc[objetivo].shift(1*24)
    df_proc["temperatura_t-1"] = df_proc["Temperatura"].shift(1*24)
    df_proc["objetivo_t-2"] = df_proc[objetivo].shift(2*24)
    df_proc["temperatura_t-2"] = df_proc["Temperatura"].shift(2*24)
    df_proc["objetivo_t-3"] = df_proc[objetivo].shift(3*24)
    df_proc["temperatura_t-3"] = df_proc["Temperatura"].shift(3*24)
    '''    
    for i in range(1, 2):  # 14 d√≠as previos
        df[f"demanda_t-{i * 24}"] = df["Demanda"].shift(i * 24)
        df[f"temperatura_t-{i * 24}"] = df["Temperatura"].shift(i * 24)
    '''
    df_proc.dropna(inplace=True)

    # Seleccionar todas las columnas que empiezan con 'demanda_t-' o 'temperatura_t-'
    #cols_modelo = [col for col in df_proc.columns if col.startswith("demanda_t-") or col.startswith("temperatura_t-")]

    # Tambi√©n incluir la temperatura actual
    #cols_modelo.append("Temperatura")

    X = df_proc[["Temperatura","objetivo_t-1", "temperatura_t-1","objetivo_t-2", "temperatura_t-2","objetivo_t-3", "temperatura_t-3"]]
    #X = df_proc[["Temperatura", "demanda_t-1", "temperatura_t-1"]]
    #X = df_proc[cols_modelo]
    X = sm.add_constant(X)
    y = df_proc[objetivo]

    modelo = sm.OLS(y, X).fit()
    df_proc["Prediccion"] = modelo.predict(X)
    """
    ultimos_dias = df_proc.tail(N_dias * 24)
    num_dias = ultimos_dias["DATE"].nunique()
    #datos_reales = torch.tensor(ultimos_dias[objetivo].values).reshape(num_dias, 24)
    datos_predichos = torch.tensor(ultimos_dias["Prediccion"].values).reshape(num_dias, 24)

    #return modelo, datos_predichos, datos_reales
    """
    # Filtrar el rango a predecir
    mask = df_proc["Dia_int"].between(dia_inicio, dia_fin)
    filas_filtradas = df_proc.loc[mask]
    array_vals = torch.tensor(filas_filtradas["Prediccion"].values).flatten().numpy()

    if len(filas_filtradas) != len(array_vals):
        raise ValueError(
            f"Tama√±o incompatible {objetivo}: {len(filas_filtradas)} filas vs {len(array_vals)} valores de cl√°sico"
        )

    # Aplicar la predicci√≥n en el DataFrame original
    df_proc.loc[mask, objetivo] = array_vals

    print(f"Finalizada predicci√≥n cl√°sica de {objetivo} para d√≠as {dia_inicio}‚Äì{dia_fin}.")
    return df_proc


def completar_datos(parametros_json, datos_emparejados, fuentes_emparejadas):
    """
    Rellena un DataFrame de series horarias incompletas usando modelos de IA o, en su defecto, regresi√≥n cl√°sica.

    A partir de un conjunto de datos hist√≥ricos y un DataFrame de ‚Äúfuentes‚Äù que indica qu√© d√≠as faltan (`"AGenerar"`),
    esta funci√≥n detecta los intervalos a generar para precio, demanda y potencia solar, elige el dispositivo (GPU/CPU)
    y el modo de predicci√≥n (IA si hay modelos preentrenados, cl√°sico en caso contrario), y aplica sucesivamente cada modelo
    para completar los huecos. Opcionalmente, guarda el resultado combinado en un CSV de salida para posteriores usos.

    ---
    \n**Flujo:**
    1) Extrae de `fuentes_emparejadas` los intervalos [`dia_inicio`, `dia_fin`] para cada variable objetivo
       (precio, demanda, potencia solar) donde aparece `"AGenerar"`, veo que rango genero para cada dato.
    2) Comprueba hardware y disponibilidad de modelos con `comprobacion_hardware_y_modo()`:
       - Si hay GPU con cuda instalado, libreria torch instalada, y modelos, usa IA v√≠a `predecir_modelo_IA`.
       - Si no, recurre al modelo cl√°sico con `predecir_modelo_clasico`.
    3) Para cada variable:
       - Anuncia por consola el inicio de la predicci√≥n.
       - Llama a la funci√≥n correspondiente, que devuelve el mismo `datos_emparejados` con la columna
         de la variable objetivo completada, el cual sera input directamente de la siguiente variable a predecir.
    4) Tras cubrir precio, demanda y solar, guarda el DataFrame resultante en
       `"DatosPython/datosEOST_prediccionIA_emparejados.csv"`.

    ---
    \n**Par√°metros:**
    - `parametros_json` (dict): Diccionario con rutas a los modelos de IA bajo
      `parametros_json["rutas_modelos_IA"]`, claves `"modelo_precio"`, `"modelo_demanda"`, `"modelo_solar"`.
    - `datos_emparejados` (pd.DataFrame): DataFrame original datos con entradas horarias, con columnas
      `"Precio"`, `"Demanda"`, `"PotenciaSolar"`, etc. Formato largo, 1 fila por hora
    - `fuentes_emparejadas` (pd.DataFrame): DataFrame con metadatos de fuentes y "que hacer" por hora de dichos datos con el mismo formato

    ---
    \n**Returns:**
    - Tuple[pd.DataFrame, pd.DataFrame]:
      - `datos_emparejados`: DataFrame con las tres columnas objetivo (`"Precio"`, `"Demanda"`, `"PotenciaSolar"`)
        completadas seg√∫n el modelo elegido (ademas de tod0 el df que ya venia sin modificar, el mismo que siempre uso pero completo con predicciones).
      - `fuentes_emparejadas`: El DataFrame de fuentes original, sin modificaciones. No lo voy a usar mas asi que no importa que haga con el una vez entra en la funcion.

    ---
    \n**Notas:**
    - Los modelos IA prueba desfasando (`offsets`) para alinear historial y √°rea de predicci√≥n.
    - El modelo cl√°sico usa regresi√≥n OLS basada en rezagos de 3 d√≠as y temperatura como baseline, un ARIMA simplificado.
    - Si no se detecta `"AGenerar"` para una variable, se omite su predicci√≥n, no hay nada que generar.
    - El CSV de salida sirve para conservar un log de la predicci√≥n IA/clave usada, pero no se usara para nada.
    """

    #cargo rutas
    ruta_modelo_demanda = parametros_json["rutas_modelos_IA"]["modelo_demanda"]
    ruta_modelo_precio = parametros_json["rutas_modelos_IA"]["modelo_precio"]
    ruta_modelo_solar = parametros_json["rutas_modelos_IA"]["modelo_solar"]


    #miro que intervalos de datos estan marcados para generar con la IA o con modelo dentro de las fuentes y los obtengo
    #(la clave, las fuentes estan alineados con los datos, asi que rangos en fuentes son rangos en datos)
    def detectar_intervalo_a_generar(fuente_df, columna_objetivo, valor_objetivo="AGenerar"):
        dias_con_objetivo = fuente_df.loc[fuente_df[columna_objetivo] == valor_objetivo, "Dia_int"]
        if not dias_con_objetivo.empty:
            return int(dias_con_objetivo.min()), int(dias_con_objetivo.max())
        else:
            return None, None

    dia_inicio_precio, dia_fin_precio = detectar_intervalo_a_generar(fuentes_emparejadas, "Precio")
    dia_inicio_demanda, dia_fin_demanda = detectar_intervalo_a_generar(fuentes_emparejadas, "Demanda")
    dia_inicio_solar, dia_fin_solar = detectar_intervalo_a_generar(fuentes_emparejadas, "PotenciaSolar")

    #print(f"dia_inicio_precio = {dia_inicio_precio}, dia_fin_precio = {dia_fin_precio}")
    #print(f"dia_inicio_demanda = {dia_inicio_demanda}, dia_fin_demanda = {dia_fin_demanda}")
    #print(f"dia_inicio_potenciasolar = {dia_inicio_solar}, dia_fin_potenciasolar = {dia_fin_solar}")

    #miro si predigo en gpu o en cpu. Cpu es mas lenta pero es factible en este problema para predecir
    tengo_gpu,tengo_modelos = comprobacion_hardware_y_modo(parametros_json)
    if tengo_gpu:
        device = "cuda"
    else:
        device = "cpu"

    #si tengo los 3 modelos puedo usar la IA (ya sea en cpu o en gpu). Si falta alguno asumo que pueden estar comprometidos los otros, uso el modelo matematico directamente
    if tengo_modelos:
        #dentro de la funcion me genero una mascara y edito el df completandolo, y lo retorno con solo eso cambiado. Voy pasando el df de datos de funcion a funcion tipo ping pong completando en cada paso los datos que necesite
        print("\n-> Iniciando prediccion de precios futuros con IA. Esto puede tomar unos segundos.")
        datos_emparejados = predecir_modelo_IA(dia_inicio_precio, dia_fin_precio, ruta_modelo_precio, datos_emparejados, "Precio", device=device)

        print("\n-> Iniciando prediccion de demandas futuras con IA. Esto puede tomar unos segundos.")
        datos_emparejados = predecir_modelo_IA(dia_inicio_demanda, dia_fin_demanda, ruta_modelo_demanda, datos_emparejados, "Demanda", device=device)

        print("\n-> Iniciando prediccion de irradancias futuras con IA. Esto puede tomar unos segundos.")
        datos_emparejados = predecir_modelo_IA(dia_inicio_solar, dia_fin_solar, ruta_modelo_solar, datos_emparejados, "PotenciaSolar", device=device)

    else:
        #dentro de la funcion me genero una mascara, edito el df completandolo, y lo retorno con solo eso cambiado. Voy pasando el df de datos de funcion a funcion tipo ping pong completando en cada paso los datos que necesite
        print("\n-> Iniciando prediccion de precios futuros con modelo clasico. Esto puede tomar unos segundos.")
        datos_emparejados = predecir_modelo_clasico(dia_inicio_precio, dia_fin_precio, datos_emparejados,"Precio")

        print("\n-> Iniciando prediccion de demandas futuras con modelo clasico. Esto puede tomar unos segundos.")
        datos_emparejados = predecir_modelo_clasico(dia_inicio_demanda, dia_fin_demanda, datos_emparejados, "Demanda")

        print("\n-> Iniciando prediccion de irradancias futuras con modelo clasico. Esto puede tomar unos segundos.")
        datos_emparejados = predecir_modelo_clasico(dia_inicio_solar, dia_fin_solar, datos_emparejados, "PotenciaSolar")



    #ya que estamos guardo el archivo con lo generado, por tener con el resto
    carpeta = "DatosPython"
    nombre_archivo = "datosEOST_prediccionIA_emparejados.csv"
    ruta_output = os.path.join(carpeta, nombre_archivo)
    datos_emparejados.to_csv(ruta_output, index=False)

    return datos_emparejados, fuentes_emparejadas


if __name__ == '__main__':
    """
    Script principal para entrenamiento y evaluaci√≥n de modelos de predicci√≥n horaria de demanda el√©ctrica,
    precio de mercado y potencia solar, empleando tanto m√©todos cl√°sicos (OLS) como modelos de IA basados en redes neuronales.
    El uso de los modelos de IA est acompletamente integrado y automatizado en el codigo, pero no la creacion de dichos modelos
    Es un proceso semi artesanal, hay que entrenar poco a poco para evitar overfitting, cada variable tiene una respuesta distinta
    asi que tampoco se pueden entrenar los 3 a la vez, y en el proceso se deben ajustas las condiciones y las penalizaciones
    para corregir el modelo y que tengan la respuesta deseada. No se puede automatizar, y ademas para entrenarlas hay que estar
    editando el codigo durante el proceso, tampoco se puede resumir a un par de activaciones de un comando.
    
    Notese que hago un "import main" eso es por que uso parte del codigo del main. Podria llevarme este codigo al main, pero aqui es mas comodo y autocontenido

    Este m√≥dulo realiza los siguientes pasos:

    1) Carga de configuraci√≥n:
       - Lee el archivo JSON de par√°metros (`DatosPython/Parametros.json`) para obtener rutas de datos,
         par√°metros de meteorolog√≠a y nombres de modelos.

    2) Inicializaci√≥n de datos hist√≥ricos:
       - Invoca funciones de `main` para descargar o cargar archivos de consumos, precios, irradiancias y temperaturas.
       - Empareja todos los historiales en un solo DataFrame horario (`datos_emparejados`).

    3) Preparaci√≥n de datos futuros:
       - Obtiene previsiones de temperatura para un rango futuro con `obtener_prediccion_temperaturas`.
       - Alinea estos datos de temperatura futuros para poder servir como entrada a modelos de IA.

    4) Evaluaci√≥n de baseline cl√°sico:
       - Ajusta un modelo de regresi√≥n lineal OLS que utiliza temperatura y tres d√≠as de lag para predecir la demanda.
       - Imprime el resumen estad√≠stico del modelo y el error cuadr√°tico medio (MSE) de las predicciones.

    5) Configuraci√≥n de ejecuci√≥n:
       - Define ventanas de d√≠as (`desfase_dias`, `N_dias`) y switches booleanos (que deben activarse y desactivarse 
        escribiendo en cada variable true o false dentro del propio codigo) para entrenar y evaluar cada modelo:
        `entrenar_demanda`, `evaluar_demanda`, `entrenar_precios`, `evaluar_precios`, `entrenar_solar`, `evaluar_solar`.

    6) Entrenamiento y evaluaci√≥n de IA:
       - Si `entrenar_*` es True, llama a `entrenar_ia(...)` para ajustar la red neuronal correspondiente.
       - Si `evaluar_*` es True, invoca `evaluar_modelo_con_df(...)` para generar predicciones IA y calcula su MSE.

    7) Visualizaci√≥n de resultados:
       - Muestra por consola los MSE de cada m√©todo (cl√°sico vs IA).
       - Traza gr√°ficos comparativos de predicciones vs valores reales para los modelos evaluados.

    Configuraci√≥n adicional:
        - Ajustar los flags `entrenar_*` y `evaluar_*` seg√∫n convenga.
        - Modificar `desfase_dias` y `N_dias` para cambiar el horizonte de predicci√≥n.
        - Dentro de la funcion de `entrenar_dual_input()`, en la parte de CONDICIONES, cambiar los parametros de loss para  
        entrenar el modelo para que "aprenda bien". Seran necesarios distintos parametros en distintas etapas del entrenamiento
    """

    print("prediccion_valores_ia ejecutado como main -> iniciando entrenamiento o evaluacion de un modelo de IA")
    import main



    ruta_json_parametros = "DatosPython/Parametros.json"
    # cargo json y leo fechas
    with open(ruta_json_parametros, "r") as f:
        parametros = json.load(f)


    ruta_consumos = main.inicializar_consumos_historicos(parametros)
    # print(ruta_consumos_historicos)

    ruta_precios = main.inicializar_precios_historicos(parametros)
    # print(ruta_precios_historicos)

    ruta_solar = main.inicializar_irradiancias_historicos(parametros)
    # print(ruta_solar_historicos)

    ruta_temperaturas = main.inicializar_temperaturas_historicos(parametros)
    # print(ruta_temperaturas_historicos)

    datos_emparejados = main.inicializar_vector_emparejados_historicos(parametros, ruta_consumos, ruta_precios,
                                                                       ruta_solar, ruta_temperaturas)
    # print(datos_historicos_emparejados)



    #datos futuros
    #aun no lo uso pero ya lo tengo preparado para usar como input de prediccion
    latitud = parametros["param_temperaturas"]["latitud"]
    longitud = parametros["param_temperaturas"]["longitud"]
    zona_horaria = parametros["param_temperaturas"]["zona_horaria"]
    dateIni_str = "29-04-25"
    dateEnd_str =  "30-04-25"
    fechas_str, datos_temperatura = temperaturas.obtener_prediccion_temperaturas(latitud, longitud, zona_horaria, dateIni_str, dateEnd_str,formato="%d-%m-%y")
    #df_futuro = emparejarEO.alinear_datos_futuros_IA(parametros, datos_temperatura, fechas_str)


    #--------------------------------------


    desfase_dias = 0 #limitador de la fecha maxima, numero de dias que tengo datos menos ese desfase
    N_dias = 30  # dias que evaluo a futuro

    entrenar_demanda = False
    evaluar_demanda = False
    entrenar_precios = False
    evaluar_precios = False
    entrenar_solar = False
    evaluar_solar = False




    #PREDICCION DEAMANDA CLASICA (CON MODELO MATEMATICO ESTILO ARIMA)
    modelo, demanda_matematica, demanda_real = prediccion_matematica_horaria(datos_emparejados, N_dias, dia_inicio=731 - 365 - desfase_dias, dia_fin=731 - desfase_dias, key_historicos="Demanda")
    print("RESUMEN MODELO MATEMATICO PREDICCION DEMANDA:")
    print(modelo.summary())
    error_matematico_demandda = F.mse_loss(demanda_matematica, demanda_real) #calcula el MSE respecto al real


    #PREDICCION DEMANDA CON IA
    modelo_ia = "modelo_demanda_casa.pt"
    #modelo_ia = "quicksaves_modelo_modelo_demanda_casa/modelo_epoch20000.pt"
    if entrenar_demanda: entrenar_ia(modelo_ia,"Demanda", dia_inicio=1, dia_fin=700, epochs=50000, device="cuda")
    #modelo_ia = "modelo_demanda_casa.pt"
    #modelo_ia = "quicksaves_modelo_modelo_demanda_casa/modelo_epoch10000.pt"
    if evaluar_demanda: demanda_ia, demanda_real = evaluar_modelo_con_df(modelo_ia, datos_emparejados, "Demanda",
                                                                     dia_inicio=731 - N_dias - desfase_dias,
                                                                     dia_fin=731 - desfase_dias, device="cuda")
    if evaluar_demanda: error_ia_demanda = F.mse_loss(demanda_ia, demanda_real) #calcula el MSE respecto al real





    #PREDICCION PRECIO CON IA
    modelo_ia = "modelo_precio_omie.pt"
    #modelo_ia = "quicksaves_modelo_modelo_precio_omie/modelo_epoch10000.pt"
    if entrenar_precios: entrenar_ia(modelo_ia,"Precio", dia_inicio=1, dia_fin=700, epochs=100000, device="cuda")
    #modelo_ia = "modelo_precio_omie.pt"
    #modelo_ia = "quicksaves_modelo_modelo_precio_omie/modelo_epoch30000.pt"
    if evaluar_precios: precio_ia, precio_real = evaluar_modelo_con_df(modelo_ia, datos_emparejados, "Precio",
                                                                   dia_inicio=731 - N_dias - desfase_dias,
                                                                   dia_fin=731 - desfase_dias, device="cuda")
    if evaluar_precios: error_ia_precio = F.mse_loss(precio_ia, precio_real)  # calcula el MSE respecto al real




    #PREDICCION POTENCIA SOLAR CON IA
    modelo_ia = "modelo_potencia_solar.pt"
    #modelo_ia = "quicksaves_modelo_modelo_potencia_solar/modelo_epoch20000.pt"
    if entrenar_solar: entrenar_ia(modelo_ia,"PotenciaSolar", dia_inicio=1, dia_fin=700, epochs=50000, device="cuda")
    #modelo_ia = "modelo_potencia_solar.pt"
    #modelo_ia = "quicksaves_modelo_modelo_potencia_solar/modelo_epoch20000.pt"
    if evaluar_solar: solar_ia, solar_real = evaluar_modelo_con_df(modelo_ia, datos_emparejados, "PotenciaSolar",
                                                               dia_inicio=731 - N_dias - desfase_dias,
                                                               dia_fin=731 - desfase_dias, device="cuda")
    if evaluar_solar: error_ia_solar = F.mse_loss(solar_ia, solar_real)  # calcula el MSE respecto al real



    if evaluar_demanda: print(f"MSE IA demanda          : {error_ia_demanda.item():.6f}")
    print(f"MSE Matem√°tico demanda  : {error_matematico_demandda.item():.6f}")
    if evaluar_precios: print(f"MSE IA precio           : {error_ia_precio.item():.6f}")
    if evaluar_solar: print(f"MSE IA solar            : {error_ia_solar.item():.6f}")

    if evaluar_demanda: plot_multidia(demanda_ia, demanda_real, continuar=True,titulo="Demanda casa - IA (vs real)") #demanda, con ia
    if evaluar_precios: plot_multidia(precio_ia, precio_real, continuar=True,titulo="Precio omie - IA (vs real)") #precio
    if evaluar_solar: plot_multidia(solar_ia, solar_real, continuar=True,titulo="Potencia solar - IA (vs real)") #solar
    plot_multidia(demanda_matematica, demanda_real, continuar=False,titulo="Demanda casa - Modelo matematico (vs real)") #deamnda, matematico

